[spider]
thread=10;线程数量
max_action=10240;最大action数量
debug=true;是否开启debug模式
timeout=3;http超时设置,0永不超时
delay=0;每个页面爬完后停留时间，毫秒，0不停留
enable_db=true;是否开启数据库存储,如果为true则需要配置[db]
action_record=true;是否记录失败action到mysql,就可以用fix参数修复失败记录,如果为true则需要配置[action]
enable_cookie=true;是否启用cookie
smart_cookie=false;是否启用智能管理cookie，启用后，多线程httpclient页面跳转之间的cookie传递也会和浏览器一样符合规定，但是依然无法避免不同ip的问题
enable_redirect=true;是否启用重定向，比如301,302自动跳转
enable_proxy=true;是否启用代理
change_proxy=true;每次抓取成功后是否更换代理,如果抓取失败，肯定会更换代理，无论该项是true或者false
recover_proxy=false;每次成功抓取一个页面后如果要换代理，那原先的代理是否重新回收到代理池内，如果抓取失败，该代理肯定被丢弃
change_agent=false;每次抓取后是否更换header的user-agent
proxypool_size=10;代理池容量，代理用完时会重新请求新的代理，代理池容量越大，请求频率越低
proxyserver=http://127.0.0.1:8080/httpproxies?count=10;代理服务器地址，返回json,count必须小于等于proxypool容量
proxytype=http;代理类型，http sock5两种选项
reset_httpclient=true;页面抓取失败的时候是否重置该httpclient,包括cookie,proxy等,和change_proxy有重合


[action]
type=mysql
max_open_conns=10
max_idle_conns=5
database=actions
table=action
user=root
passwd=333221
address=127.0.0.1:3306
max_respy=10;失败action重爬最大次数，超过这个数将不会从数据库中读取重爬
max_fail=5;一个action最多失败次数，失败后将写入失败记录
label=bookspider;失败action的标记

[loger]
type=netloger;日志类型,netloger是网络数据库日志,loger是普通本地日志

[logerdb]
type=mysql
max_open_conns=2000;mysql最大链接数量,0不限制
max_idle_conns=1000;mhsql最大闲置连接数量,0不限制
database=project_logs;日志数据库名称
table=test;日志数据库表名
address=127.0.0.1:3306
user=root
passwd=333221

[db]
type=mysql
max_open_conns=2000
max_idle_conns=1000
database=book
user=root
passwd=333221
address=127.0.0.1:3306